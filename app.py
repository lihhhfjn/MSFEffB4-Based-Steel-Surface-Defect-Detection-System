import os
import sys

# æ‰“å°ä¸€äº›è¯Šæ–­ä¿¡æ¯ï¼Œå¸®åŠ©æˆ‘ä»¬äº†è§£å½“å‰ç¯å¢ƒ
print("--- å¯åŠ¨ç¯å¢ƒè¯Šæ–­ ---")
print(f"Python è§£é‡Šå™¨è·¯å¾„ (sys.executable): {sys.executable}")
print(f"å½“å‰å·¥ä½œç›®å½• (os.getcwd()): {os.getcwd()}")

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨ TCL_LIBRARY ç¯å¢ƒå˜é‡ï¼Œå¦‚æœå­˜åœ¨ï¼Œæ‰“å°å®ƒçš„å€¼
if 'TCL_LIBRARY' in os.environ:
    print(f"å¯åŠ¨æ—¶å·²å­˜åœ¨ TCL_LIBRARY ç¯å¢ƒå˜é‡: {os.environ['TCL_LIBRARY']}")
if 'TK_LIBRARY' in os.environ:
    print(f"å¯åŠ¨æ—¶å·²å­˜åœ¨ TK_LIBRARY ç¯å¢ƒå˜é‡: {os.environ['TK_LIBRARY']}")
print("--------------------")

# --- å¼€å§‹å¼ºåˆ¶ä¿®æ­£ ---
# æ ¹æ®ç”¨æˆ·æä¾›çš„ç²¾ç¡®ä¿¡æ¯ï¼Œæˆ‘ä»¬ç°åœ¨ä½¿ç”¨ç»å¯¹æ­£ç¡®çš„è·¯å¾„

# 1. æ˜ç¡®å®šä¹‰æ­£ç¡®çš„åº“è·¯å¾„ (æœ€ç»ˆä¿®æ­£ç‰ˆ)
correct_tcl_path = r'D:\anaconda3\envs\dxtorch\tcl\tcl8.6'
correct_tk_path = r'D:\anaconda3\envs\dxtorch\tcl\tk8.6'

# 2. éªŒè¯è¿™ä¸ªè·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œç¡®ä¿æˆ‘ä»¬æ²¡æœ‰å†™é”™
if os.path.exists(correct_tcl_path) and os.path.exists(correct_tk_path):
    print(f"âœ… æˆåŠŸæ‰¾åˆ°æ­£ç¡®çš„Tcl/Tkåº“è·¯å¾„: {correct_tcl_path}")

    # 3. å¼ºåˆ¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥
    os.environ['TCL_LIBRARY'] = correct_tcl_path
    os.environ['TK_LIBRARY'] = correct_tk_path

    print(f"âœ… å·²å¼ºåˆ¶å°†ç¯å¢ƒå˜é‡è®¾ç½®ä¸º:")
    print(f"   - TCL_LIBRARY = {os.environ['TCL_LIBRARY']}")
    print(f"   - TK_LIBRARY  = {os.environ['TK_LIBRARY']}")
else:
    # å¦‚æœä¸Šé¢çš„è·¯å¾„ä¸å¯¹ï¼Œå°±æŠ¥é”™ï¼Œè®©æ‚¨çŸ¥é“éœ€è¦æ£€æŸ¥è·¯å¾„æ‹¼å†™
    print(f"âŒ è‡´å‘½é”™è¯¯: åœ¨æœ€ç»ˆä¿®æ­£åçš„è·¯å¾„ '{correct_tcl_path}' ä¸­ä»ç„¶æ‰¾ä¸åˆ°Tcl/Tkåº“ï¼")
    print("   è¯·å†æ¬¡æ‰‹åŠ¨åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­ç¡®è®¤è¯¥è·¯å¾„æ˜¯å¦å­˜åœ¨ã€‚")
    # ç¨‹åºæ— æ³•ç»§ç»­ï¼Œç›´æ¥é€€å‡º
    sys.exit(1)

print("--- ç¯å¢ƒä¿®å¤å®Œæˆï¼Œå¼€å§‹åŠ è½½ä¸»ç¨‹åº ---")

import gradio as gr
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torchvision import models
import psutil
# 'os' is already imported above
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import warnings
import json
from datetime import datetime
import tkinter as tk
from tkinter import filedialog
import threading

# å¿½ç•¥ä¸€äº›å…¼å®¹æ€§è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# Severstalé’¢é“ç¼ºé™·ç±»åˆ«å®šä¹‰ - ä¸è®­ç»ƒä»£ç ä¿æŒä¸€è‡´
DEFECT_CLASSES = {
    0: "æ— ç¼ºé™·",
    1: "éº»ç‚¹è¡¨é¢ç¼ºé™·",
    2: "é¾Ÿè£‚ç¼ºé™·",
    3: "åˆ’ç—•ç¼ºé™·",
    4: "æ–‘å—ç¼ºé™·"
}

# å®Œæ•´çš„ç±»åˆ«æ ‡ç­¾
DEFECT_LABELS = [
    "æ— ç¼ºé™·",
    "éº»ç‚¹è¡¨é¢ç¼ºé™·",
    "é¾Ÿè£‚ç¼ºé™·",
    "åˆ’ç—•ç¼ºé™·",
    "æ–‘å—ç¼ºé™·"
]

# é»˜è®¤æ¨¡å‹è·¯å¾„
DEFAULT_MODEL_PATH = "./models/best.pth"


# ==================== æ¨¡å‹æƒé‡ç®¡ç† ====================
def get_default_model_path():
    """è·å–é»˜è®¤æ¨¡å‹è·¯å¾„"""
    return DEFAULT_MODEL_PATH


def check_default_model():
    """æ£€æŸ¥é»˜è®¤æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
    default_path = get_default_model_path()
    exists = os.path.exists(default_path)
    return exists, default_path


def validate_model_file(model_path):
    """éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
    if not model_path or not os.path.exists(model_path):
        return False, "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"

    if not model_path.endswith(('.pth', '.pt')):
        return False, "æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œéœ€è¦.pthæˆ–.ptæ–‡ä»¶"

    try:
        # å°è¯•åŠ è½½æ¨¡å‹æ–‡ä»¶æ£€æŸ¥æ˜¯å¦æŸå
        checkpoint = torch.load(model_path, map_location='cpu')
        return True, "æ¨¡å‹æ–‡ä»¶éªŒè¯æˆåŠŸ"
    except Exception as e:
        return False, f"æ¨¡å‹æ–‡ä»¶æŸå: {str(e)}"


def get_model_path_to_use(uploaded_file):
    """ç¡®å®šè¦ä½¿ç”¨çš„æ¨¡å‹è·¯å¾„"""
    if uploaded_file is not None:
        # ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶ï¼Œä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶
        return uploaded_file.name, "ç”¨æˆ·ä¸Šä¼ "
    else:
        # ç”¨æˆ·æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„
        default_exists, default_path = check_default_model()
        if default_exists:
            return default_path, "é»˜è®¤è·¯å¾„"
        else:
            return None, "æœªæ‰¾åˆ°æ¨¡å‹"


# ==================== ç¡¬ä»¶æ£€æµ‹ä¸ä¿¡æ¯å±•ç¤º ====================
def detect_hardware():
    """æ£€æµ‹ç¡¬ä»¶ä¿¡æ¯"""
    hardware_info = {
        'cuda_available': torch.cuda.is_available(),
        'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,
        'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
        'gpu_info': [],
        'cpu_info': {
            'cores': psutil.cpu_count(logical=False),
            'threads': psutil.cpu_count(logical=True),
            'memory_gb': round(psutil.virtual_memory().total / (1024 ** 3), 1)
        },
        'recommended_device': 'cpu'
    }

    if hardware_info['cuda_available']:
        try:
            for i in range(hardware_info['gpu_count']):
                gpu_props = torch.cuda.get_device_properties(i)
                gpu_info = {
                    'id': i,
                    'name': gpu_props.name,
                    'memory_gb': round(gpu_props.total_memory / (1024 ** 3), 1),
                }
                hardware_info['gpu_info'].append(gpu_info)
            hardware_info['recommended_device'] = 'cuda:0'
        except Exception as e:
            print(f"GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
            hardware_info['cuda_available'] = False

    return hardware_info


def get_device_options(hardware_info):
    """ç”Ÿæˆè®¾å¤‡é€‰æ‹©é€‰é¡¹"""
    options = ['cpu']
    if hardware_info['cuda_available']:
        for i in range(hardware_info['gpu_count']):
            options.append(f'cuda:{i}')
    return options


def create_hardware_info_html(hardware_info):
    """åˆ›å»ºç¡¬ä»¶ä¿¡æ¯HTMLæ˜¾ç¤º"""
    html = "<div style='padding: 15px; background: #f8f9fa; border-radius: 8px; margin: 10px 0;'>"
    if hardware_info['cuda_available']:
        html += "<h3 style='color: #28a745; margin-top: 0;'>ğŸš€ GPUåŠ é€Ÿå¯ç”¨</h3>"
        for i, gpu in enumerate(hardware_info['gpu_info']):
            html += f"<p><strong>GPU {i}:</strong> {gpu['name']} ({gpu['memory_gb']:.1f}GB VRAM)</p>"
    else:
        html += "<h3 style='color: #ffc107; margin-top: 0;'>âš ï¸ ä»…CPUæ¨¡å¼</h3>"
        html += "<p>æœªæ£€æµ‹åˆ°CUDAå…¼å®¹çš„GPUï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œæ¨ç†</p>"
    html += f"<p><strong>CPU:</strong> {hardware_info['cpu_info']['threads']}çº¿ç¨‹ | "
    html += f"<strong>ç³»ç»Ÿå†…å­˜:</strong> {hardware_info['cpu_info']['memory_gb']:.1f}GB</p>"
    html += "</div>"
    return html


def create_model_status_html():
    """åˆ›å»ºæ¨¡å‹çŠ¶æ€ä¿¡æ¯HTML"""
    default_exists, default_path = check_default_model()

    html = "<div style='padding: 10px; background: #e8f4fd; border-radius: 6px; margin: 5px 0;'>"
    html += "<h4 style='margin: 0 0 10px 0; color: #0066cc;'>ğŸ“¦ æ¨¡å‹åŠ è½½ç­–ç•¥</h4>"

    if default_exists:
        html += f"<p style='margin: 5px 0; color: #28a745;'>âœ… <strong>é»˜è®¤æ¨¡å‹å·²å°±ç»ª:</strong> {default_path}</p>"
        html += "<p style='margin: 5px 0; color: #666;'>â€¢ å¦‚æœä¸ä¸Šä¼ æ–‡ä»¶ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨é»˜è®¤æ¨¡å‹</p>"
        html += "<p style='margin: 5px 0; color: #666;'>â€¢ ä¸Šä¼ æ–‡ä»¶åå°†ä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„æ¨¡å‹</p>"
    else:
        html += f"<p style='margin: 5px 0; color: #dc3545;'>âŒ <strong>é»˜è®¤æ¨¡å‹ä¸å­˜åœ¨:</strong> {default_path}</p>"
        html += "<p style='margin: 5px 0; color: #dc3545;'>â€¢ è¯·ä¸Šä¼ æ¨¡å‹æƒé‡æ–‡ä»¶æ‰èƒ½å¼€å§‹æ£€æµ‹</p>"

    html += "</div>"
    return html


# ==================== åˆ†ç±»æ¨¡å‹æ¶æ„ ====================
class DualAttention(nn.Module):
    def __init__(self, in_channels, reduction=8):
        super().__init__()
        self.channel_attn = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(in_channels, in_channels // reduction, 1),
                                          nn.ReLU(), nn.Conv2d(in_channels // reduction, in_channels, 1), nn.Sigmoid())
        self.spatial_attn = nn.Sequential(nn.Conv2d(in_channels, 1, kernel_size=7, padding=3), nn.Sigmoid())

    def forward(self, x):
        return x * self.channel_attn(x) * self.spatial_attn(x)


class MSFModule(nn.Module):
    def __init__(self, channels_list, out_channels=256):
        super().__init__()
        self.conv1 = nn.Conv2d(channels_list[0], out_channels, 1)
        self.conv2 = nn.Conv2d(channels_list[1], out_channels, 1)
        self.conv3 = nn.Conv2d(channels_list[2], out_channels, 1)
        self.upsample2 = nn.ConvTranspose2d(out_channels, out_channels, 4, stride=2, padding=1)
        self.upsample3 = nn.ConvTranspose2d(out_channels, out_channels, 8, stride=4, padding=2)
        self.fusion = nn.Conv2d(out_channels * 3, out_channels, 1)
        self.relu = nn.ReLU()
        self.dual_attention = DualAttention(out_channels)

    def forward(self, x1, x2, x3):
        f1 = self.conv1(x1)
        f2 = self.conv2(x2)
        f3 = self.conv3(x3)
        f2 = self.upsample2(f2)
        f3 = self.upsample3(f3)
        min_size = min(f1.size()[2:], f2.size()[2:], f3.size()[2:])
        f1 = F.interpolate(f1, size=min_size, mode='bilinear', align_corners=False)
        f2 = F.interpolate(f2, size=min_size, mode='bilinear', align_corners=False)
        f3 = F.interpolate(f3, size=min_size, mode='bilinear', align_corners=False)
        fused = self.fusion(torch.cat([f1, f2, f3], dim=1))
        fused = self.relu(fused)
        fused = self.dual_attention(fused)
        return fused


class MSFEffB4(nn.Module):
    def __init__(self, n_cls=5):
        super().__init__()
        self.backbone = models.efficientnet_b4(weights='IMAGENET1K_V1')
        self.stage2 = nn.Sequential(*list(self.backbone.features)[:3])
        self.stage4 = nn.Sequential(*list(self.backbone.features)[3:5])
        self.stage6 = nn.Sequential(*list(self.backbone.features)[5:])
        channels_list = [32, 112, 1792]
        self.msf = MSFModule(channels_list, out_channels=256)
        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Dropout(0.3), nn.Linear(256, n_cls))

    def forward(self, x):
        f1 = self.stage2(x)
        f2 = self.stage4(f1)
        f3 = self.stage6(f2)
        fused = self.msf(f1, f2, f3)
        return self.classifier(fused)


# ==================== æ¨¡å‹åŠ è½½ä¸å›¾åƒå¤„ç† ====================
def load_trained_model(model_class, model_path, device='cpu', **kwargs):
    """é€šç”¨æ¨¡å‹åŠ è½½å‡½æ•°"""
    try:
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        model = model_class(**kwargs).to(device)
        checkpoint = torch.load(model_path, map_location=device)
        state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint))
        missing, unexpected = model.load_state_dict(state_dict, strict=False)
        if missing: print(f"è­¦å‘Š: ç¼ºå¤±çš„æƒé‡é”®: {missing[:5]}...")
        if unexpected: print(f"è­¦å‘Š: æ„å¤–çš„æƒé‡é”®: {unexpected[:5]}...")
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
    except Exception as e:
        raise Exception(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")


def get_image_transforms():
    return transforms.Compose([
        transforms.Resize((256, 1024)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])


def preprocess_image(image_path, transform):
    try:
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = Image.fromarray(image_path).convert('RGB')
        return transform(image).unsqueeze(0), image
    except Exception as e:
        raise Exception(f"å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {str(e)}")


# ==================== åˆ†ç±»æ¨ç†æ ¸å¿ƒé€»è¾‘ ====================
def predict_single_image_classification(model, image_tensor, device, threshold=0.5):
    try:
        model.eval()
        image_tensor = image_tensor.to(device)
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = torch.sigmoid(outputs).cpu().numpy()[0]

        predictions = (probabilities > threshold).astype(int)
        if not any(predictions[1:]):
            predictions[0] = 1
        else:
            predictions[0] = 0

        detected_defects = sorted([{'class_id': i, 'class_name': DEFECT_LABELS[i], 'confidence': prob}
                                   for i, (pred, prob) in enumerate(zip(predictions, probabilities)) if pred == 1],
                                  key=lambda x: x['confidence'], reverse=True)

        percentage_display = "    ".join(
            [f"{label}: {prob * 100:.1f}%" for label, prob in zip(DEFECT_LABELS, probabilities)])

        return {
            'probabilities': probabilities.tolist(),
            'predictions': predictions.tolist(),
            'percentage_display': percentage_display,
            'detected_defects': detected_defects
        }
    except Exception as e:
        print(f"åˆ†ç±»é¢„æµ‹è¿‡ç¨‹è¯¦ç»†é”™è¯¯: {str(e)}")
        return None


# ==================== ä¿å­˜ç»“æœå‡½æ•° ====================
def save_classification_results_to_txt(results, image_name, output_folder):
    try:
        os.makedirs(output_folder, exist_ok=True)
        txt_path = os.path.join(output_folder, os.path.splitext(image_name)[0] + '_cls.txt')
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(f"é’¢é“ç¼ºé™·åˆ†ç±»ç»“æœ - {image_name}\n{'=' * 60}\n")
            f.write(f"æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            detected_defects = results.get('detected_defects', [])
            if any(d['class_id'] != 0 for d in detected_defects):
                f.write("ğŸ” æ£€æµ‹åˆ°çš„ç¼ºé™·:\n")
                for defect in detected_defects:
                    if defect['class_id'] != 0:
                        f.write(f"  - {defect['class_name']}: {defect['confidence'] * 100:.1f}%\n")
            else:
                f.write("âœ… æ­£å¸¸ (æ— ç¼ºé™·)\n")

            f.write(f"\nğŸ“Š å„ç±»åˆ«ç½®ä¿¡åº¦:\n{results.get('percentage_display', 'æ•°æ®å¼‚å¸¸')}\n")
        return txt_path
    except Exception as e:
        raise Exception(f"ä¿å­˜åˆ†ç±»ç»“æœå¤±è´¥: {str(e)}")


# ==================== æ‰¹é‡æ¨ç†ä¸ä¸»é€»è¾‘ ====================
def perform_classification_task(cls_weights, input_type, single_image, image_folder, output_folder, device, batch_size,
                                confidence_threshold, progress_callback=None):
    """æ‰§è¡Œåˆ†ç±»ä»»åŠ¡"""
    # ç¡®å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹æ–‡ä»¶
    model_path, source_type = get_model_path_to_use(cls_weights)

    if model_path is None:
        return "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ã€‚è¯·ä¸Šä¼ æ¨¡å‹æƒé‡æ–‡ä»¶æˆ–ç¡®ä¿é»˜è®¤æ¨¡å‹å­˜åœ¨ã€‚"

    # éªŒè¯æ¨¡å‹æ–‡ä»¶
    is_valid, msg = validate_model_file(model_path)
    if not is_valid:
        return f"âŒ æ¨¡å‹æ–‡ä»¶éªŒè¯å¤±è´¥ï¼š{msg}"

    status_msg = f"ğŸ“¥ æ­£åœ¨åŠ è½½åˆ†ç±»æ¨¡å‹ ({source_type})...\n"
    status_msg += f"ğŸ“‚ æ¨¡å‹è·¯å¾„: {model_path}\n"

    try:
        cls_model = load_trained_model(MSFEffB4, model_path, device, n_cls=5)
        status_msg += f"âœ… åˆ†ç±»æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {device})\n\n"
    except Exception as e:
        return f"âŒ åˆ†ç±»æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"

    image_paths, image_names = [], []
    if input_type == "single":
        image_paths, image_names = [single_image.name], [os.path.basename(single_image.name)]
    else:
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        for file_path in Path(image_folder).glob('*'):
            if file_path.suffix.lower() in supported_formats:
                image_paths.append(str(file_path))
                image_names.append(file_path.name)

    total_images = len(image_paths)
    if total_images == 0:
        return "âŒ é”™è¯¯ï¼šåœ¨æŒ‡å®šè·¯å¾„ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡ã€‚"

    status_msg += f"ğŸ” å¼€å§‹å¤„ç† {total_images} å¼ å›¾ç‰‡...\n"
    transform = get_image_transforms()
    results_summary = []

    for i, (image_path, image_name) in enumerate(zip(image_paths, image_names)):
        try:
            image_tensor, _ = preprocess_image(image_path, transform)
            results = predict_single_image_classification(cls_model, image_tensor, device, confidence_threshold)
            if results:
                txt_path = save_classification_results_to_txt(results, image_name, output_folder)
                results_summary.append({'image_name': image_name, 'results': results, 'txt_path': txt_path})
            if progress_callback:
                progress_callback((i + 1) / total_images, f"å·²å¤„ç† {i + 1}/{total_images}")
        except Exception as e:
            status_msg += f"å¤„ç†å›¾ç‰‡ {image_name} æ—¶å‡ºé”™: {str(e)}\n"
            continue

    status_msg += f"\nğŸ¯ åˆ†ç±»æ¨ç†å®Œæˆ! å…±å¤„ç† {len(results_summary)}/{total_images} å¼ å›¾ç‰‡ã€‚\n"
    status_msg += f"ğŸ“ ç»“æœä¿å­˜è·¯å¾„: {output_folder}\n\n"
    status_msg += "ğŸ“‹ ç»“æœé¢„è§ˆ (æœ€å¤šæ˜¾ç¤º5æ¡):\n" + "-" * 60 + "\n"
    for item in results_summary[:5]:
        detected = item['results']['detected_defects']
        defect_str = " | ".join(
            [f"{d['class_name']}({d['confidence'] * 100:.1f}%)" for d in detected if d['class_id'] != 0])
        if not defect_str:
            defect_str = "æ­£å¸¸ (æ— ç¼ºé™·)"

        status_msg += f"ğŸ“· {item['image_name']} -> ğŸ” ä¸»è¦åˆ¤å®š: {defect_str}\n"

        all_confidences = item['results'].get('percentage_display', 'ä¿¡åº¦ä¿¡æ¯ä¸å¯ç”¨')
        status_msg += f"   ğŸ“Š è¯¦ç»†ç½®ä¿¡åº¦: {all_confidences}\n\n"

    if len(results_summary) > 5: status_msg += "...\n"

    return status_msg


def run_inference(cls_weights, input_type, single_image, image_folder, output_folder, device,
                  batch_size, confidence_threshold):
    """ä¸»æ¨ç†å‡½æ•°"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹
        model_path, source_type = get_model_path_to_use(cls_weights)
        if model_path is None:
            return "âŒ é”™è¯¯ï¼šè¯·ä¸Šä¼ åˆ†ç±»æ¨¡å‹æƒé‡æ–‡ä»¶æˆ–ç¡®ä¿é»˜è®¤æ¨¡å‹æ–‡ä»¶å­˜åœ¨äº ./models/best.pth"

        if input_type == "single" and single_image is None:
            return "âŒ é”™è¯¯ï¼šè¯·é€‰æ‹©è¾“å…¥å›¾ç‰‡ã€‚"
        if input_type == "folder" and (not image_folder or not os.path.exists(image_folder)):
            return "âŒ é”™è¯¯ï¼šè¯·æŒ‡å®šä¸€ä¸ªæœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚"

        valid, output_path_or_error = validate_and_create_output_folder(output_folder)
        if not valid:
            return f"âŒ é”™è¯¯ï¼š{output_path_or_error}"
        output_folder = output_path_or_error

        return perform_classification_task(cls_weights, input_type, single_image, image_folder, output_folder,
                                           device, batch_size, confidence_threshold)

    except Exception as e:
        return f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}"


# ==================== UI è¾…åŠ©å‡½æ•° ====================
def update_model_status():
    """æ›´æ–°æ¨¡å‹çŠ¶æ€æ˜¾ç¤º"""
    return create_model_status_html()


def toggle_input_visibility(input_type):
    if input_type == "single":
        return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)
    else:
        return gr.update(visible=False), gr.update(visible=True), gr.update(visible=True)


def browse_folder(title="é€‰æ‹©æ–‡ä»¶å¤¹"):
    try:
        root = tk.Tk()
        root.withdraw()
        root.attributes('-topmost', True)
        folder_path = filedialog.askdirectory(title=title, initialdir=os.getcwd())
        root.destroy()
        return folder_path if folder_path else ""
    except Exception as e:
        # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        print(f"!!! tkinteræ–‡ä»¶å¤¹é€‰æ‹©å¤±è´¥: {e}")
        # å¯ä»¥è¿”å›ä¸€ä¸ªé”™è¯¯æç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“é—®é¢˜æ‰€åœ¨
        return f"é”™è¯¯: {e}"


def validate_and_create_output_folder(output_path):
    try:
        if not output_path or output_path.strip() == "": output_path = "./output"
        os.makedirs(output_path, exist_ok=True)
        test_file = os.path.join(output_path, "test_write.tmp")
        with open(test_file, 'w') as f:
            f.write("test")
        os.remove(test_file)
        return True, output_path
    except Exception as e:
        return False, f"åˆ›å»ºæˆ–å†™å…¥è¾“å‡ºæ–‡ä»¶å¤¹å¤±è´¥: {str(e)}"


# ==================== åˆ›å»ºä¸»ç•Œé¢ ====================
def create_interface():
    hardware_info = detect_hardware()
    device_options = get_device_options(hardware_info)
    hardware_html = create_hardware_info_html(hardware_info)
    model_status_html = create_model_status_html()

    with gr.Blocks(title="é’¢é“ç¼ºé™·åˆ†ç±»æ£€æµ‹ç³»ç»Ÿ") as interface:
        gr.Markdown("# ğŸ­ é’¢é“ç¼ºé™·åˆ†ç±»æ£€æµ‹ç³»ç»Ÿ")
        gr.Markdown("### åŸºäºæ·±åº¦å­¦ä¹ çš„ç¼ºé™·æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ")
        gr.HTML(hardware_html)

        with gr.Row():
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“‚ 1. æ¨¡å‹æƒé‡é€‰æ‹©")
                model_status_display = gr.HTML(model_status_html)
                cls_weights = gr.File(
                    label="ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹æƒé‡ (å¯é€‰)",
                    file_types=[".pth", ".pt"],
                    value=None
                )
                gr.Markdown("ğŸ’¡ **è¯´æ˜**: å¦‚æœä¸ä¸Šä¼ æ–‡ä»¶ä¸”é»˜è®¤æ¨¡å‹å­˜åœ¨ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨é»˜è®¤æ¨¡å‹")

            with gr.Column(scale=3):
                gr.Markdown("### âš™ï¸ 2. é…ç½®æ¨ç†å‚æ•°")
                with gr.Row():
                    device_choice = gr.Dropdown(choices=device_options, value=hardware_info['recommended_device'],
                                                label="æ¨ç†è®¾å¤‡")
                    confidence_threshold = gr.Slider(minimum=0.1, maximum=0.9, value=0.5, step=0.05,
                                                     label="åˆ†ç±»ç½®ä¿¡åº¦é˜ˆå€¼")
                    batch_size = gr.Slider(minimum=1, maximum=32, value=4, step=1, label="æ‰¹å¤„ç†å¤§å°")

        gr.Markdown("### ğŸ–¼ï¸ 3. é€‰æ‹©è¾“å…¥æ•°æ®")
        with gr.Row():
            with gr.Column():
                input_type = gr.Radio(choices=[("å•å¼ å›¾ç‰‡", "single"), ("æ‰¹é‡å¤„ç†", "folder")], value="single",
                                      label="è¾“å…¥æ¨¡å¼")
                single_image = gr.File(label="é€‰æ‹©å•å¼ å›¾ç‰‡", file_types=["image"], visible=True)
                image_folder = gr.Textbox(label="å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„", placeholder="ç‚¹å‡»'æµè§ˆ'é€‰æ‹©æˆ–æ‰‹åŠ¨è¾“å…¥", visible=False)
                folder_browse_btn = gr.Button("ğŸ“‚ æµè§ˆè¾“å…¥æ–‡ä»¶å¤¹", visible=False, size="sm")
            with gr.Column():
                output_folder = gr.Textbox(label="è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„", value="./output")
                output_browse_btn = gr.Button("ğŸ“‚ æµè§ˆè¾“å‡ºæ–‡ä»¶å¤¹", size="sm")

        gr.Markdown("### ğŸš€ 4. å¼€å§‹æ£€æµ‹")
        start_inference_btn = gr.Button("ğŸš€ å¼€å§‹åˆ†ç±»æ£€æµ‹", variant="primary", size="lg")
        inference_status = gr.Textbox(label="æ¨ç†çŠ¶æ€ä¸ç»“æœ", lines=20, placeholder="ç­‰å¾…å¼€å§‹...", interactive=False)

        # --- äº‹ä»¶ç»‘å®š ---
        input_type.change(toggle_input_visibility, inputs=[input_type],
                          outputs=[single_image, image_folder, folder_browse_btn])
        folder_browse_btn.click(lambda: browse_folder("é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹"), outputs=[image_folder])
        output_browse_btn.click(lambda: browse_folder("é€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹"), outputs=[output_folder])

        # å½“ç”¨æˆ·ä¸Šä¼ æˆ–æ¸…é™¤æ–‡ä»¶æ—¶ï¼Œæ›´æ–°æ¨¡å‹çŠ¶æ€æ˜¾ç¤º
        cls_weights.change(fn=update_model_status, outputs=[model_status_display])

        start_inference_btn.click(
            fn=run_inference,
            inputs=[
                cls_weights, input_type, single_image, image_folder,
                output_folder, device_choice, batch_size, confidence_threshold
            ],
            outputs=[inference_status]
        )
    return interface















































def main():
    print("ğŸš€ å¯åŠ¨é’¢é“ç¼ºé™·åˆ†ç±»æ£€æµ‹ç³»ç»Ÿ...")

    # å¯åŠ¨æ—¶æ£€æŸ¥é»˜è®¤æ¨¡å‹çŠ¶æ€
    default_exists, default_path = check_default_model()
    if default_exists:
        print(f"âœ… æ£€æµ‹åˆ°é»˜è®¤æ¨¡å‹: {default_path}")
    else:
        print(f"âš ï¸ é»˜è®¤æ¨¡å‹ä¸å­˜åœ¨: {default_path}")
        print("   ç”¨æˆ·éœ€è¦ä¸Šä¼ æ¨¡å‹æ–‡ä»¶æ‰èƒ½è¿›è¡Œæ¨ç†")

    try:
        interface = create_interface()
        interface.launch(server_name="127.0.0.1", server_port=7861, inbrowser=True)
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")


if __name__ == "__main__":
    main()